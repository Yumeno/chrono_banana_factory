import { GoogleGenerativeAI } from '@google/generative-ai'
import { ImageGenerationRequest, GeneratedImage, ImageEditRequest, TimelineResponse, ContentPart } from '@/types'
import { getEnvironmentVariable, getEnvironmentDebugInfo } from '@/lib/env'

class NanoBananaClient {
  private readonly apiKey: string
  private readonly ai: GoogleGenerativeAI
  private lastRequestTime = 0
  private readonly rateLimitDelay = 8000 // 8 seconds between requests

  constructor() {
    // WindowsÁí∞Â¢É„Åß„ÅÆÁ¢∫ÂÆü„Å™Áí∞Â¢ÉÂ§âÊï∞ÂèñÂæó
    const apiKey = this.getApiKey()
    
    if (!apiKey) {
      throw new Error(this.getDetailedErrorMessage())
    }
    this.apiKey = apiKey
    this.ai = new GoogleGenerativeAI(this.apiKey) // Ê≠£„Åó„ÅÑÂàùÊúüÂåñÊñπÊ≥ï
  }

  private getApiKey(): string | undefined {
    // „Éñ„É©„Ç¶„Ç∂Áí∞Â¢É„Åß„ÅØ NEXT_PUBLIC_ „Éó„É¨„Éï„Ç£„ÉÉ„ÇØ„Çπ„ÅåÂøÖË¶Å
    const isClient = typeof window !== 'undefined'
    
    let apiKey: string | undefined
    
    if (isClient) {
      // „ÇØ„É©„Ç§„Ç¢„É≥„Éà„Çµ„Ç§„Éâ„Åß„ÅØ NEXT_PUBLIC_ Áâà„ÅÆ„ÅøÂà©Áî®ÂèØËÉΩ
      apiKey = process.env.NEXT_PUBLIC_GEMINI_API_KEY
    } else {
      // „Çµ„Éº„Éê„Éº„Çµ„Ç§„Éâ„Åß„ÅØ‰∏°ÊñπË©¶Ë°å
      apiKey = getEnvironmentVariable('GEMINI_API_KEY') || 
               getEnvironmentVariable('NEXT_PUBLIC_GEMINI_API_KEY')
    }

    // „Éá„Éê„ÉÉ„Ç∞ÊÉÖÂ†±„Çí„Ç≥„É≥„ÇΩ„Éº„É´„Å´Âá∫ÂäõÔºàÈñãÁô∫ÊôÇ„ÅÆ„ÅøÔºâ
    if (process.env.NODE_ENV === 'development') {
      console.log('üîç Enhanced API Key Detection:')
      const debugInfo = getEnvironmentDebugInfo()
      console.log(JSON.stringify(debugInfo, null, 2))
      
      if (apiKey) {
        console.log(`‚úÖ API Key found: ${apiKey.slice(0, 8)}...${apiKey.slice(-4)}`)
      } else {
        console.log('‚ùå No API Key found through any method')
      }
    }

    return apiKey
  }

  private getDetailedErrorMessage(): string {
    const isWindows = process.platform === 'win32'
    const baseMessage = 'GEMINI_API_KEY environment variable is required.'
    
    if (isWindows) {
      return `${baseMessage}

üîß Windows Setup Instructions:

PowerShell (Êé®Â•®):
  $env:GEMINI_API_KEY="your_api_key_here"
  npm run dev

Command Prompt:
  set GEMINI_API_KEY=your_api_key_here
  npm run dev

Or create .env.local file:
  echo GEMINI_API_KEY=your_api_key_here > .env.local
  npm run dev

üåê Get API Key: https://aistudio.google.com/apikey`
    }

    return `${baseMessage}

Setup Instructions:
  export GEMINI_API_KEY="your_api_key_here"
  npm run dev

Or create .env.local file:
  echo "GEMINI_API_KEY=your_api_key_here" > .env.local
  npm run dev

üåê Get API Key: https://aistudio.google.com/apikey`
  }

  async generateImage(request: ImageGenerationRequest): Promise<GeneratedImage | GeneratedImage[]> {
    this.validateRequest(request)
    await this.enforceRateLimit()

    console.log('üì§ [API REQUEST] Starting image generation')
    console.log('üìù [PROMPT] Text:', request.prompt)
    
    // Check if we have images to include
    if (request.images && request.images.length > 0) {
      console.log('üñºÔ∏è [IMAGES] Sending', request.images.length, 'reference images:')
      
      // Build contents array with text prompt and images
      const contents = [
        { text: request.prompt },
        ...request.images.map((img, index) => {
          // Use base64 property for UploadedImage type
          const imageData = img.base64 || (img as any).data
          const imageName = img.name || 'unnamed'
          console.log(`  ${index + 1}. ${imageName} (${img.mimeType}, ${Math.round(imageData.length / 1024)}KB)`)
          return {
            inlineData: {
              mimeType: img.mimeType,
              data: imageData
            }
          }
        })
      ]
      
      console.log('üìä [ORDER] Final content order:')
      console.log('  1. Text prompt')
      request.images.forEach((img, i) => {
        const isWhiteBlank = img.name?.includes('white-blank')
        console.log(`  ${i + 2}. ${isWhiteBlank ? '‚¨ú WHITE BLANK' : 'üñºÔ∏è USER IMAGE'}: ${img.name}`)
      })

      const model = this.ai.getGenerativeModel({ model: request.model })
      const response = await model.generateContent(contents)
      
      return this.parseResponse(response, request)
    } else {
      console.log('üñºÔ∏è [IMAGES] No reference images')
      const model = this.ai.getGenerativeModel({ model: request.model })
      const response = await model.generateContent(request.prompt)
      
      return this.parseResponse(response, request)
    }
  }

  async editImage(request: ImageEditRequest): Promise<GeneratedImage | GeneratedImage[]> {
    this.validateEditRequest(request)
    await this.enforceRateLimit()

    // Build contents array with text prompt and images
    const contents = [
      { text: request.prompt },
      ...request.images.map((img, index) => ({
        inlineData: {
          mimeType: img.mimeType,
          data: img.data
        }
      }))
    ]

    console.log('üîç [DEBUG] Final API request structure:')
    console.log('üîç [DEBUG] Model:', request.model)
    console.log('üîç [DEBUG] Contents array length:', contents.length)
    console.log('üîç [DEBUG] Contents structure:', contents.map((item, index) => {
      if ('text' in item) {
        return `${index}: text (${item.text.length} chars)`
      } else if ('inlineData' in item) {
        return `${index}: image (${item.inlineData.mimeType}, ${item.inlineData.data.length} chars)`
      }
      return `${index}: unknown`
    }))

    const model = this.ai.getGenerativeModel({ model: request.model })
    const response = await model.generateContent(contents)

    return this.parseResponse(response, request)
  }

  private validateRequest(request: ImageGenerationRequest | ImageEditRequest): void {
    if (!request.prompt || request.prompt.trim().length === 0) {
      throw new Error('Prompt cannot be empty')
    }
    
    if (request.prompt.length > 2000) {
      throw new Error('Prompt too long (max 2000 characters)')
    }
  }

  private validateEditRequest(request: ImageEditRequest): void {
    this.validateRequest(request)
    
    if (!request.images || request.images.length === 0) {
      throw new Error('At least one image is required for editing')
    }
    
    // Note: Removed 3-image limit based on Phase 2.6 experiment
    // Actual Gemini API supports 10+ images despite hackathon documentation

    // Validate each image
    for (const image of request.images) {
      if (!image.data || !image.mimeType) {
        throw new Error('Each image must have data and mimeType')
      }
      
      const validMimeTypes = ['image/png', 'image/jpeg', 'image/jpg', 'image/webp']
      if (!validMimeTypes.includes(image.mimeType)) {
        throw new Error(`Unsupported image type: ${image.mimeType}`)
      }
    }
  }

  private async enforceRateLimit(): Promise<void> {
    const now = Date.now()
    const timeSinceLastRequest = now - this.lastRequestTime
    
    if (timeSinceLastRequest < this.rateLimitDelay) {
      const waitTime = this.rateLimitDelay - timeSinceLastRequest
      await new Promise(resolve => setTimeout(resolve, waitTime))
    }
    
    this.lastRequestTime = Date.now()
  }


  private parseResponse(response: any, request: ImageGenerationRequest | ImageEditRequest): GeneratedImage | GeneratedImage[] {
    // Log the raw response for debugging
    console.log('üîç Raw API Response:', JSON.stringify(response, null, 2))
    
    // Handle response from GoogleGenerativeAI SDK
    const result = response.response || response
    
    if (!result) {
      throw new Error('No response data received from API')
    }

    // Try to get text content from the response
    let textContent = ''
    try {
      textContent = result.text?.() || ''
    } catch (e) {
      console.log('Could not extract text from response:', e)
    }

    // Check if response contains candidates with parts
    if (result.candidates?.[0]?.content?.parts) {
      const images: GeneratedImage[] = []
      
      // Collect all images from the response
      result.candidates[0].content.parts.forEach((part: any, index: number) => {
        // Check for inline data (base64 encoded image)
        if (part.inlineData) {
          const { mimeType, data } = part.inlineData

          if (!mimeType || !data) {
            console.log(`‚ö†Ô∏è Skipping invalid image data at index ${index}`)
            return
          }

          const imageUrl = `data:${mimeType};base64,${data}`
          console.log(`‚úÖ [IMAGE ${index}] Found image: ${mimeType}, size: ${data.length} bytes`)

          images.push({
            id: this.generateId(),
            imageUrl,
            prompt: request.prompt,
            model: request.model,
            createdAt: new Date(),
            metadata: {
              mimeType,
              processingTime: Date.now() - this.lastRequestTime,
              imageIndex: index,
              // Include text content if any (for mixed responses)
              textResponse: textContent || undefined
            }
          })
        }
      })
      
      // Return array if multiple images, single image if one
      if (images.length > 1) {
        console.log(`üé® [MULTI-IMAGE] Returning ${images.length} images`)
        return images
      } else if (images.length === 1) {
        return images[0]
      }
    }

    // If we only have text, return a special response indicating text-only
    if (textContent) {
      console.log('üìù [TEXT RESPONSE] API returned text instead of image')
      console.log('Text content:', textContent)
      
      // Return a text-only response that the UI can handle
      return {
        id: this.generateId(),
        imageUrl: '', // Empty string to indicate no image
        prompt: request.prompt,
        model: request.model,
        createdAt: new Date(),
        metadata: {
          mimeType: 'text/plain',
          processingTime: Date.now() - this.lastRequestTime,
          textResponse: textContent,
          isTextOnly: true
        }
      }
    }

    throw new Error('No content found in API response. The request may have been blocked or failed.')
  }

  // Phase 2.5: Parse multi-modal response into timeline format
  private parseTimelineResponse(response: unknown, request: ImageGenerationRequest): TimelineResponse {
    
    const typedResponse = response as {
      candidates?: Array<{
        content?: {
          parts?: Array<{
            text?: string
            inlineData?: {
              mimeType: string
              data: string
            }
          }>
        }
      }>
    }
    
    if (!typedResponse?.candidates?.[0]?.content?.parts) {
      throw new Error('Invalid API response format: missing candidates or content')
    }

    const parts = typedResponse.candidates[0].content.parts
    const contentParts: ContentPart[] = []
    const baseTimestamp = new Date()

    parts.forEach((part, index) => {
      if (part.text) {
        contentParts.push({
          type: 'text',
          content: part.text,
          order: index,
          timestamp: new Date(baseTimestamp.getTime() + index * 1000) // 1 second apart
        })
      } else if (part.inlineData) {
        const { mimeType, data } = part.inlineData
        if (mimeType && data) {
          const imageUrl = `data:${mimeType};base64,${data}`
          contentParts.push({
            type: 'image',
            content: imageUrl,
            order: index,
            timestamp: new Date(baseTimestamp.getTime() + index * 1000)
          })
        }
      }
    })

    const textParts = contentParts.filter(p => p.type === 'text').length
    const imageParts = contentParts.filter(p => p.type === 'image').length

    const timelineResponse: TimelineResponse = {
      id: this.generateId(),
      parts: contentParts,
      prompt: request.prompt,
      createdAt: baseTimestamp,
      metadata: {
        model: request.model,
        processingTime: Date.now() - this.lastRequestTime,
        totalParts: contentParts.length,
        textParts,
        imageParts
      }
    }

    return timelineResponse
  }

  // Phase 2.5: Generate timeline-based multi-modal content
  async generateTimeline(request: ImageGenerationRequest): Promise<TimelineResponse> {
    this.validateRequest(request)
    await this.enforceRateLimit()

    const model = this.ai.getGenerativeModel({ model: request.model })
    const response = await model.generateContent(request.prompt)

    return this.parseTimelineResponse(response, request)
  }

  // Suggestion generation for story/scene text
  async generateSuggestion(request: {
    prompt: string
    images?: Array<{ data: string; mimeType: string }>
  }): Promise<{ suggestion: string; model: string; metadata?: any }> {
    await this.enforceRateLimit()
    
    console.log('üé® [SUGGESTION API] Starting text generation')
    console.log('üìù [SUGGESTION API] Prompt length:', request.prompt.length)
    console.log('üñºÔ∏è [SUGGESTION API] Images:', request.images?.length || 0)
    
    try {
      // Use Gemini 1.5 Flash for text generation (faster and cheaper than image model)
      const model = this.ai.getGenerativeModel({ 
        model: 'gemini-1.5-flash',
        generationConfig: {
          temperature: 0.8,
          topK: 40,
          topP: 0.95,
          maxOutputTokens: 2048,
        }
      })
      
      // Build contents array
      const contents: any[] = [{ text: request.prompt }]
      
      // Add images if provided
      if (request.images && request.images.length > 0) {
        request.images.forEach((img, index) => {
          console.log(`  üì∑ Image ${index + 1}: ${img.mimeType}`)
          contents.push({
            inlineData: {
              mimeType: img.mimeType,
              data: img.data
            }
          })
        })
      }
      
      // Generate content
      const response = await model.generateContent(contents)
      
      // Extract text from response
      const result = response.response
      const text = result.text()
      
      if (!text) {
        throw new Error('No text generated from API')
      }
      
      console.log('‚úÖ [SUGGESTION API] Generated text length:', text.length)
      
      return {
        suggestion: text,
        model: 'gemini-1.5-flash',
        metadata: {
          processingTime: Date.now() - this.lastRequestTime,
          outputLength: text.length
        }
      }
    } catch (error) {
      console.error('‚ùå [SUGGESTION API] Generation failed:', error)
      
      // Handle specific errors
      if (error instanceof Error) {
        if (error.message.includes('SAFETY')) {
          throw new Error('Content was blocked by safety filters. Please modify your input.')
        }
        if (error.message.includes('429')) {
          throw new Error('API rate limit reached. Please wait a moment and try again.')
        }
      }
      
      throw error
    }
  }

  private generateId(): string {
    const timestamp = Date.now()
    const randomPart1 = Math.random().toString(36).substr(2, 9)
    const randomPart2 = Math.random().toString(36).substr(2, 5)
    const performanceNow = performance.now().toString().replace('.', '')
    return `img_${timestamp}_${randomPart1}_${randomPart2}_${performanceNow}`
  }

  // Method to check if the client is ready
  isReady(): boolean {
    return !!this.apiKey
  }

  // Method to validate API Key format
  validateApiKey(): { valid: boolean; message: string } {
    if (!this.apiKey) {
      return { valid: false, message: 'API Key not found' }
    }

    if (this.apiKey.length < 10) {
      return { valid: false, message: 'API Key too short (likely invalid)' }
    }

    if (!this.apiKey.startsWith('AIza')) {
      return { valid: false, message: 'API Key format invalid (should start with "AIza")' }
    }

    return { valid: true, message: 'API Key format appears valid' }
  }

  // Method to test API connection
  async testConnection(): Promise<{ success: boolean; message: string; details?: unknown }> {
    try {
      const validation = this.validateApiKey()
      if (!validation.valid) {
        return { success: false, message: validation.message }
      }

      // Simple test request with minimal prompt
      const model = this.ai.getGenerativeModel({ model: 'gemini-2.5-flash-image-preview' })
      const response = await model.generateContent('test image of a simple red dot')

      // Check if response contains image data
      const testResponse = response as {
        candidates?: Array<{
          content?: {
            parts?: Array<{
              inlineData?: {
                mimeType: string
                data: string
              }
            }>
          }
        }>
      }
      if (testResponse?.candidates?.[0]?.content?.parts) {
        for (const part of testResponse.candidates[0].content.parts) {
          if (part.inlineData) {
            return { success: true, message: 'Connection successful' }
          }
        }
      }

      return { success: false, message: 'No image data received in test response' }
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : 'Unknown error'
      return { 
        success: false, 
        message: `Connection failed: ${errorMessage}`, 
        details: error 
      }
    }
  }

  // Get debug information
  getDebugInfo(): Record<string, unknown> {
    const validation = this.validateApiKey()
    const rateLimitStatus = this.getRateLimitStatus()
    
    return {
      apiKeyStatus: {
        present: !!this.apiKey,
        maskedKey: this.apiKey ? `${this.apiKey.slice(0, 6)}***${this.apiKey.slice(-4)}` : 'Not found',
        validation: validation
      },
      rateLimiting: rateLimitStatus,
      client: {
        sdk: 'GoogleGenAI official SDK',
        rateLimitDelay: this.rateLimitDelay,
        lastRequestTime: this.lastRequestTime
      },
      environment: {
        platform: process.platform,
        nodeEnv: process.env.NODE_ENV,
        isServer: typeof window === 'undefined'
      }
    }
  }

  // Method to get rate limit status
  getRateLimitStatus(): { canMakeRequest: boolean; waitTime: number } {
    const now = Date.now()
    const timeSinceLastRequest = now - this.lastRequestTime
    const canMakeRequest = timeSinceLastRequest >= this.rateLimitDelay
    const waitTime = canMakeRequest ? 0 : this.rateLimitDelay - timeSinceLastRequest

    return { canMakeRequest, waitTime }
  }
}

// ÈÅÖÂª∂ÂàùÊúüÂåñ„Åß„Ç§„É≥„Çπ„Çø„É≥„Çπ„ÇíÁÆ°ÁêÜ
let _nanoBananaClient: NanoBananaClient | null = null

export const nanoBananaClient = {
  // ÂÆüÈöõ„ÅÆ‰ΩøÁî®ÊôÇ„Å´ÂàùÊúüÂåñ
  get instance(): NanoBananaClient {
    // Only initialize on client side to avoid hydration issues
    if (typeof window === 'undefined') {
      throw new Error('nanoBananaClient can only be used on the client side')
    }
    
    if (!_nanoBananaClient) {
      _nanoBananaClient = new NanoBananaClient()
    }
    return _nanoBananaClient
  },

  // API„É°„ÇΩ„ÉÉ„Éâ„Çí„Éó„É≠„Ç≠„Ç∑
  async generateImage(request: ImageGenerationRequest): Promise<GeneratedImage | GeneratedImage[]> {
    return this.instance.generateImage(request)
  },

  async editImage(request: ImageEditRequest): Promise<GeneratedImage | GeneratedImage[]> {
    return this.instance.editImage(request)
  },

  async generateTimeline(request: ImageGenerationRequest): Promise<TimelineResponse> {
    return this.instance.generateTimeline(request)
  },

  async generateSuggestion(request: { prompt: string; images?: Array<{ data: string; mimeType: string }> }): Promise<{ suggestion: string; model: string; metadata?: any }> {
    return this.instance.generateSuggestion(request)
  },

  isReady(): boolean {
    try {
      if (typeof window === 'undefined') return false
      return this.instance.isReady()
    } catch {
      return false
    }
  },

  validateApiKey(): { valid: boolean; message: string } {
    try {
      if (typeof window === 'undefined') {
        return { valid: false, message: 'Server-side validation not supported' }
      }
      return this.instance.validateApiKey()
    } catch {
      return { valid: false, message: 'Client initialization failed' }
    }
  },

  async testConnection(): Promise<{ success: boolean; message: string; details?: unknown }> {
    try {
      if (typeof window === 'undefined') {
        return { success: false, message: 'Server-side connection test not supported' }
      }
      return await this.instance.testConnection()
    } catch (error) {
      return { 
        success: false, 
        message: error instanceof Error ? error.message : 'Unknown error',
        details: error 
      }
    }
  },

  getDebugInfo(): Record<string, unknown> {
    try {
      if (typeof window === 'undefined') {
        return {
          error: 'Server-side debug info not supported',
          environment: {
            platform: 'server',
            nodeEnv: process.env.NODE_ENV,
            isServer: true
          }
        }
      }
      return this.instance.getDebugInfo()
    } catch (error) {
      return {
        error: 'Failed to initialize client',
        details: error instanceof Error ? error.message : 'Unknown error',
        environment: {
          platform: typeof window === 'undefined' ? 'server' : 'browser',
          nodeEnv: process.env.NODE_ENV,
          isServer: typeof window === 'undefined'
        }
      }
    }
  },

  getRateLimitStatus(): { canMakeRequest: boolean; waitTime: number } {
    try {
      if (typeof window === 'undefined') {
        return { canMakeRequest: false, waitTime: 0 }
      }
      return this.instance.getRateLimitStatus()
    } catch {
      return { canMakeRequest: false, waitTime: 0 }
    }
  },

  // „Ç§„É≥„Çπ„Çø„É≥„Çπ„Çí„É™„Çª„ÉÉ„ÉàÔºà„Éá„Éê„ÉÉ„Ç∞Áî®Ôºâ
  reset(): void {
    _nanoBananaClient = null
  }
}